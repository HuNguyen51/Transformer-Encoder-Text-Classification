{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import các module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pyvi import ViTokenizer\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tôi là sinh_viên'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dùng để in ra tiến trình xử lý\n",
    "def print_progress(index, total):\n",
    "    sys.stdout.write('\\r')\n",
    "    # the exact output you're looking for:\n",
    "    sys.stdout.write(str(round(index*100/total, 1))+'%')\n",
    "    sys.stdout.flush()\n",
    "# dùng để làm sạch dữ liệu như đưa về chữ viết thường, bỏ ký tự đặc biệt và bỏ những khoảng trắng dư thừa rồi áp dụng word_seg trong tiếng Việt\n",
    "def make_clean(string):\n",
    "    res = string.lower()\n",
    "    res = re.sub(r'[!“”\"#$%&\\()*+,-./:;<=>?@[\\]^_`{|}~]', \" \", res)\n",
    "    res = re.sub(r'\\s+', ' ', res).strip()\n",
    "    res = ViTokenizer.tokenize(res)\n",
    "    return res\n",
    "\n",
    "make_clean('Tôi     là(*(*%$sinh (*&viên')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data Train\n",
    "[label, path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = []\n",
    "ROOT_PATH = 'Train_Full'\n",
    "tree_path = os.walk(ROOT_PATH)\n",
    "\n",
    "for (dirpath, dirname, filenames) in tree_path:\n",
    "    if dirpath == ROOT_PATH: \n",
    "        continue\n",
    "    label = dirpath.split('\\\\')[1]\n",
    "    for filename in filenames:\n",
    "        data_path.append([label, os.path.join(dirpath, filename)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Chinh tri Xa hoi', 'Train_Full\\\\Chinh tri Xa hoi\\\\XH_NLD_ (3672).txt'],\n",
       " ['Chinh tri Xa hoi', 'Train_Full\\\\Chinh tri Xa hoi\\\\XH_NLD_ (3673).txt'],\n",
       " ['Chinh tri Xa hoi', 'Train_Full\\\\Chinh tri Xa hoi\\\\XH_NLD_ (3674).txt']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[label, text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    }
   ],
   "source": [
    "total = len(data_path)\n",
    "index = 1\n",
    "\n",
    "train = []\n",
    "for label, path in data_path:\n",
    "    print_progress(index, total)\n",
    "    index+=1\n",
    "    with open(path, 'r', encoding='utf-16') as f:\n",
    "        text = f.read().strip()\n",
    "        text = make_clean(text)\n",
    "        train.append([label, text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train, columns=['label', 'text']).to_csv('train.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data Test\n",
    "same as Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = []\n",
    "ROOT_PATH = 'Test_Full'\n",
    "tree_path = os.walk(ROOT_PATH)\n",
    "\n",
    "for (dirpath, dirname, filenames) in tree_path:\n",
    "    if dirpath == ROOT_PATH: \n",
    "        continue\n",
    "    label = dirpath.split('\\\\')[1]\n",
    "    for filename in filenames:\n",
    "        data_path.append([label, os.path.join(dirpath, filename)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    }
   ],
   "source": [
    "total = len(data_path)\n",
    "index = 1\n",
    "\n",
    "test = []\n",
    "for label, path in data_path:\n",
    "    print_progress(index, total)\n",
    "    index+=1\n",
    "    with open(path, 'r', encoding='utf-16') as f:\n",
    "        text = f.read().strip()\n",
    "        text = make_clean(text)\n",
    "        test.append([label, text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test, columns=['label', 'text']).to_csv('test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
